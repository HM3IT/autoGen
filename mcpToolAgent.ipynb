{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "import os \n",
    "\n",
    "\n",
    "model = os.environ[\"LLM_MODEL_NAME\"]\n",
    "api_key = os.environ[\"LLM_API_KEY\"]\n",
    "base_url = os.environ[\"OLLAMA_ENDPOINT\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided URL does not seem to have been processed correctly.\n",
      "\n",
      "To summarize the content of https://en.wikipedia.org/wiki/Seattle:\n",
      "\n",
      "The Seattle article on Wikipedia covers a wide range of topics related to the city, including its history, geography, climate, education, economy, culture, and attractions. Here are some key points:\n",
      "\n",
      "- History: Seattle was founded in 1851 and grew rapidly due to its favorable location near the Puget Sound and the Cascade Mountains.\n",
      "- Geography: The city lies on a narrow isthmus between Puget Sound and Lake Washington.\n",
      "- Climate: Seattle's climate is mild and temperate, with rainfall throughout the year.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\n",
    "\n",
    "# Get the fetch tool from mcp-server-fetch.\n",
    "fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"])\n",
    "tools = await mcp_server_tools(fetch_mcp_server)\n",
    "\n",
    "# Create an agent that can use the fetch tool.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=model,\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    "    model_info={\n",
    "        \"family\": \"llama\",\n",
    "        \"vision\": False,\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "    },\n",
    ")\n",
    "agent = AssistantAgent(name=\"fetcher\", model_client=model_client, tools=tools, reflect_on_tool_use=True)  # type: ignore\n",
    "\n",
    "# Let the agent fetch the content of a URL and summarize it.\n",
    "result = await agent.run(\n",
    "    task=\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\"\n",
    ")\n",
    "print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\")\n",
    "tool = LangChainToolAdapter(PythonAstREPLTool(locals={\"df\": df}))\n",
    " \n",
    "agent = AssistantAgent(\n",
    "    \"assistant\", tools=[tool], model_client=model_client, system_message=\"Use the `df` variable to access the dataset.\"\n",
    ")\n",
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"What's the average age of the passengers?\", source=\"user\")], CancellationToken()\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "I am happy.\n",
      "---------- assistant ----------\n",
      "{\n",
      "  \"thoughts\": \"You are happy\",\n",
      "  \"response\": \"happy\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='I am happy.', type='TextMessage'), TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=36, completion_tokens=22), metadata={}, content='{\\n  \"thoughts\": \"You are happy\",\\n  \"response\": \"happy\"\\n}', type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# The response format for the agent as a Pydantic base model.\n",
    "class AgentResponse(BaseModel):\n",
    "    thoughts: str\n",
    "    response: Literal[\"happy\", \"sad\", \"neutral\"]\n",
    "    \n",
    "\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=model,\n",
    "    api_key=api_key,\n",
    "    base_url=base_url,\n",
    "    model_info={\n",
    "        \"family\": \"llama\",\n",
    "        \"vision\": False,\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "    },\n",
    "    response_format=AgentResponse\n",
    ")\n",
    "    \n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Categorize the input as happy, sad, or neutral following the JSON format.\",\n",
    "    model_client_stream= True\n",
    ")\n",
    "\n",
    "await Console(agent.run_stream(task=\"I am happy.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='assistant' models_usage=None metadata={} content='{' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' ' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='\"' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='t' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ho' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ugh' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='t' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='s' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='\":' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' \"' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='Cities' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' in' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' South' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' America' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.\",' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' \"' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='response' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='\":' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' \"' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='s' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ad' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='\"' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' }\\n' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='   ' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' ' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='\\t\\t\\t\\t\\t\\t   ' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='\\t\\t' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='\\t' type='ModelClientStreamingChunkEvent'\n",
      "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=0, completion_tokens=0), metadata={}, content='{ \"thoughts\": \"Cities in South America.\", \"response\": \"sad\" }\\n    \\t\\t\\t\\t\\t\\t   \\t\\t\\t', type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "streaming_assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    model_client_stream=True,  # Enable streaming tokens.\n",
    ")\n",
    "\n",
    "\n",
    "async for message in streaming_assistant.on_messages_stream(  # type: ignore\n",
    "    [TextMessage(content=\"Name two cities in South America\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    "):\n",
    "    print(message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
